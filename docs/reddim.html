<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="es" xml:lang="es"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>4&nbsp; Técnicas de reducción de la dimensionalidad – Aprendizaje Automático</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./aprnosup.html" rel="next">
<link href="./eda.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Sin resultados",
    "search-matching-documents-text": "documentos encontrados",
    "search-copy-link-title": "Copiar el enlace en la búsqueda",
    "search-hide-matches-text": "Ocultar resultados adicionales",
    "search-more-match-text": "resultado adicional en este documento",
    "search-more-matches-text": "resultados adicionales en este documento",
    "search-clear-button-title": "Borrar",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancelar",
    "search-submit-button-title": "Enviar",
    "search-label": "Buscar"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./reddim.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Técnicas de reducción de la dimensionalidad</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Alternar barra lateral" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Buscar" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Aprendizaje Automático</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Buscar"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Prefacio</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introducción</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./data.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Datos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eda.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Análisis Exploratorio de Datos</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reddim.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Técnicas de reducción de la dimensionalidad</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./aprnosup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Aprendizaje no supervisado</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./eval.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Medidas de rendimiento</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./aprsup.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Aprendizaje supervisado</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./reglas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Reglas de asociación</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./nuevas.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Nuevas tendencias</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./conclusiones.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Conclusiones</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliografía</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Tabla de contenidos</h2>
   
  <ul>
  <li><a href="#análisis-de-componentes-principales-pca-1" id="toc-análisis-de-componentes-principales-pca-1" class="nav-link active" data-scroll-target="#análisis-de-componentes-principales-pca-1"><span class="header-section-number">4.1</span> Análisis de Componentes Principales (PCA)</a>
  <ul class="collapse">
  <li><a href="#pca-en-r" id="toc-pca-en-r" class="nav-link" data-scroll-target="#pca-en-r"><span class="header-section-number">4.1.1</span> PCA en R</a></li>
  </ul></li>
  <li><a href="#interpretación-y-limitaciones" id="toc-interpretación-y-limitaciones" class="nav-link" data-scroll-target="#interpretación-y-limitaciones"><span class="header-section-number">4.2</span> Interpretación y limitaciones</a></li>
  <li><a href="#selección-de-características" id="toc-selección-de-características" class="nav-link" data-scroll-target="#selección-de-características"><span class="header-section-number">4.3</span> Selección de características</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-reddim" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Técnicas de reducción de la dimensionalidad</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>En el análisis de datos deportivos es habitual trabajar con conjuntos de datos que incluyen <strong>muchas variables simultáneamente</strong>: métricas físicas (carga externa e interna), indicadores técnicos (pases, tiros, pérdidas), variables contextuales (rival, local/visitante, ritmo de juego), o descriptores derivados de tracking y sensores. Esta riqueza de información es valiosa, pero también introduce dificultades prácticas: variables altamente correlacionadas, redundancia, ruido y una complejidad que puede dificultar tanto el análisis exploratorio como la construcción de modelos fiables. No es raro encontrarse con decenas —o cientos— de variables por jugador, sesión o partido.</p>
<p>En este contexto cobran especial interés las <strong>técnicas de reducción de la dimensionalidad</strong>, cuyo objetivo es representar los datos en un espacio de menor dimensión conservando, en la medida de lo posible, la información relevante. En términos intuitivos, se trata de sustituir un conjunto grande de variables originales por un conjunto más pequeño de <strong>componentes</strong> o <strong>factores latentes</strong> que capturen la estructura principal de variación presente en los datos. Estas técnicas permiten simplificar la representación del rendimiento o del comportamiento deportivo sin tener que ignorar por completo la complejidad del fenómeno.</p>
<p>Las ventajas en deporte son claras. En primer lugar, facilitan la <strong>visualización</strong> y la exploración: por ejemplo, representar perfiles de jugadores o sesiones de entrenamiento en dos o tres dimensiones para detectar agrupamientos, transiciones o valores atípicos. En segundo lugar, ayudan a mitigar problemas comunes en modelización deportiva, como la <strong>multicolinealidad</strong> (por ejemplo, múltiples métricas de carga que reflejan el mismo patrón subyacente) y el riesgo de sobreajuste cuando el número de variables crece respecto al número de observaciones. Además, pueden servir como etapa previa a tareas de ML como clustering, clasificación o detección de anomalías.</p>
<p>Ahora bien, estas técnicas también tienen una limitación relevante en un máster orientado al deporte: la <strong>interpretabilidad</strong>. Los componentes reducidos suelen ser combinaciones de variables originales y, aunque pueden capturar patrones estadísticos de forma eficiente, no siempre se traducen directamente en conceptos deportivos claros (“intensidad”, “fatiga”, “control del juego”, etc.). Por ello, su uso responsable exige combinar el análisis matemático con conocimiento del dominio: interpretar los componentes, validar que tienen sentido deportivo y evitar conclusiones excesivas basadas únicamente en proyecciones en baja dimensión.</p>
<p>Despliega los paneles siguientes para descrubir algunas de las técnicas más conocidas.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Análisis de Componentes Principales (PCA)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>PCA es una de las técnicas más populares para la reducción de la dimensión. Transforma las variables originales en un nuevo conjunto de variables no correlacionadas llamadas componentes principales. Estos componentes capturan la mayor parte de la variabilidad en los datos y se pueden utilizar para representar los datos en un espacio de menor dimensión.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Análisis de factor
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Similar a PCA, el análisis de factor busca identificar variables latentes o factores subyacentes que expliquen las relaciones entre las variables originales. Es útil cuando se sospecha que las variables observadas están influenciadas por factores no observados.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Reducción de la dimensión basada en selección
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Esta técnica implica seleccionar un subconjunto de variables originales en función de algún criterio, como su importancia para el problema o su capacidad de explicar la variabilidad. Algunos métodos de selección incluyen la selección de características y la eliminación de características redundantes.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Análisis Discriminante Lineal (LDA)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>LDA es una técnica que se utiliza en problemas de clasificación. Busca encontrar una combinación lineal de variables que maximice la separación entre clases en el conjunto de datos, lo que puede reducir la dimensión al tiempo que preserva la información relevante para la clasificación.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Descomposición en Valores Singulares (SVD)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>SVD es una técnica matricial que se utiliza en la factorización de matrices y la reducción de la dimensión. Es fundamental en métodos como PCA y puede utilizarse para reducir la dimensión de matrices de datos.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
t-Distributed Stochastic Neighbor Embedding (t-SNE)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>t-SNE es una técnica de reducción de la dimensión no lineal que se utiliza comúnmente para visualización de datos. Tiene la capacidad de preservar relaciones locales entre puntos en un espacio de menor dimensión.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Autoencoders
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Los autoencoders son redes neuronales que se utilizan para aprender representaciones de datos de alta dimensión en un espacio de menor dimensión. Son especialmente útiles en problemas de reducción de la dimensión no lineal.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Reducción de la dimensión basada en la ingeniería de características
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>A veces, la reducción de la dimensión se puede lograr mediante la ingeniería de características (<strong>Feature Engineering</strong>), donde se crean nuevas variables que resumen la información de las originales de manera más efectiva.</p>
</div>
</div>
</div>
<p>En este tema, exploraremos en detalle las técnicas más utilizadas para la reducción de la dimensión, proporcionando ejemplos prácticos y pautas para su aplicación efectiva. Estas técnicas son esenciales para cualquier analista de datos que desee extraer conocimiento valioso de grandes conjuntos de datos y simplificar el proceso de análisis sin perder de vista la interpretación de los resultados.</p>
<p>Por tanto, podemos decir que los métodos de reducción de dimensionalidad son técnicas que se utilizan para reducir la cantidad de variables en un conjunto de datos mientras se intenta retener la información relevante. Sin embargo, existen enfoques adicionales para realizar la reducción de la dimensionalidad, que se clasifican comúnmente en tres categorías: <em>filter</em>, <em>wrapper</em> y <em>embedded</em> <span class="citation" data-cites="john1994irrelevant">(<a href="references.html#ref-john1994irrelevant" role="doc-biblioref">John, Kohavi, y Pfleger 1994</a>)</span>.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Métodos filter
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Los métodos filter son técnicas de selección de características que se aplican antes de entrenar un modelo de ML. Estos métodos evalúan la relación entre cada variable y la variable objetivo (o alguna medida de relevancia) sin tener en cuenta un modelo específico. Los métodos <em>filter</em> utilizan estadísticas, métricas de rendimiento, pruebas de hipótesis u otras técnicas para clasificar las características en función de su relevancia. Algunos ejemplos de métodos <em>filter</em> incluyen la correlación de Pearson, la información mutua y la prueba estadística chi-cuadrado. La principal ventaja de los métodos <em>filter</em> es su eficiencia computacional, ya que no requieren entrenar modelos.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-10-contents" aria-controls="callout-10" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Métodos wrapper
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-10" class="callout-10-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Los métodos <em>wrapper</em> también son técnicas de selección de características, pero al contrario que los métodos <em>filter</em>, utilizan modelos de ML as características. Se evalúan múltiples modelos mediante procedimientos que añaden y/o eliminan variables predictoras para encontrar la combinación óptima que maximice el rendimiento del modelo. Los métodos <em>wrapper</em> pueden ser más precisos que los métodos <em>filter</em>, ya que tienen en cuenta la interacción entre las características, pero tienden a ser más computacionalmente costosos, ya que involucran el entrenamiento repetido de modelos.</p>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Métodos embedded:
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Los métodos <em>embedded</em> incorporan la selección de características directamente en el proceso de entrenamiento de un modelo de ML. En lugar de realizar la selección de características como un paso separado, estos métodos evalúan la relevancia de las características mientras se ajustan al modelo. Esto significa que las características se seleccionan o ponderan automáticamente durante el entrenamiento del modelo. Ejemplos de métodos <em>embedded</em> incluyen la regresión L1 (Lasso), que impone penalizaciones a los coeficientes de las características menos importantes, y los métodos de árboles de decisión, que pueden evaluar la importancia de las características durante la construcción del árbol.</p>
</div>
</div>
</div>
<p>La elección entre métodos <em>filter</em>, <em>wrapper</em> y <em>embedded</em> depende de la naturaleza del problema, el conjunto de datos y las necesidades específicas del análisis. Cada enfoque tiene sus propias ventajas y desventajas, y es importante considerar factores como la eficiencia computacional, la calidad del modelo y la interpretabilidad al seleccionar el enfoque adecuado para la reducción de la dimensionalidad en un proyecto de ciencia de datos o ML.</p>
<section id="análisis-de-componentes-principales-pca-1" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="análisis-de-componentes-principales-pca-1"><span class="header-section-number">4.1</span> Análisis de Componentes Principales (PCA)</h2>
<p>Tal y como se ha indicado, el Análisis de Componentes Principales (PCA, en inglés, <em>Principal Component Analysis</em>) es una técnica de reducción de la dimensionalidad cuyo principal objetivo es simplificar la estructura de datos, preservando al mismo tiempo la mayor cantidad posible de información relevante. PCA logra esto transformando un conjunto de variables correlacionadas en un conjunto nuevo de variables no correlacionadas llamadas componentes principales.</p>
<p>Los pasos para aplicar esta técnica sobre un conjunto de datos son:</p>
<ol type="1">
<li><p><strong>Cálculo de la matriz de covarianza:</strong> El primer paso en PCA implica calcular la matriz de covarianza de las variables originales. La covarianza es una medida de cómo dos variables cambian juntas. Una matriz de covarianza muestra cómo todas las variables del conjunto de datos se relacionan entre sí.</p></li>
<li><p><strong>Obtención de los componentes principales:</strong> A continuación, se calculan los autovectores y autovalores de la matriz de covarianza. Los autovectores son las direcciones en las cuales los datos tienen la mayor varianza, y los autovalores representan la cantidad de varianza explicada por cada autovector. Probablemente hayas estudiado técnicas para el cálculo de autovectores y autovalores en cursos de Álgebra anteriores.</p></li>
<li><p><strong>Selección de componentes principales:</strong> Después de calcular los autovectores y autovalores, se ordenan en orden descendente según la cantidad de varianza que explican. Esto implica que el primer componente principal explica la mayor varianza en los datos, el segundo componente principal explica la segunda mayor varianza (una vez eliminada la variabilidad explicada por el primer componente principal), y así sucesivamente. Por lo general, se selecciona un número pequeño (¡reducción de la dimensión!) de componentes principales que capturen una cantidad significativa de la varianza total.</p></li>
<li><p><strong>Transformación de datos:</strong> Finalmente, los datos originales se transforman en el espacio de los componentes principales. Esto significa que las variables originales se combinan linealmente para formar nuevas variables (los componentes principales) que son ortogonales entre sí. Es decir, se crean nuevas variables, como combinación lineal de las originales, con la particularidad de que esas nuevas variables son incorreladas y de varianza <span class="math inline">\(1\)</span>. Por lo tanto, estos componentes principales no tienen multicolinealidad, lo que es útil en análisis posteriores.</p></li>
</ol>
<p>El PCA se utiliza en diversas aplicaciones, como reducción de dimensionalidad, compresión de imágenes, análisis de datos, reconocimiento de patrones, etc. Permite simplificar datos complejos mientras se retiene la mayor cantidad posible de información importante. Al seleccionar un número apropiado de componentes principales, es posible reducir la dimensionalidad de los datos sin perder significado, lo que puede mejorar la eficiencia del análisis y la visualización.</p>
<p><strong>Profundicemos un poco más</strong></p>
<p>El PCA busca encontrar una representación más eficiente (menor dimensión) de los datos preservando la información contenida en ellos. La idea fundamental es que <strong>la varianza de los datos representa la cantidad de información que contienen</strong>, y PCA rota el sistema de coordenadas para encontrar las direcciones en las que la varianza es máxima.</p>
<div class="callout callout-style-default callout-caution callout-titled" title="Para recordar">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Para recordar
</div>
</div>
<div class="callout-body-container callout-body">
<p>Relación entre los conceptos de varianza e información.</p>
</div>
</div>
<p>Formalmente, dado un conjunto de datos con <span class="math inline">\(p\)</span> variables, la técnica busca transformar estas variables en un nuevo conjunto de <span class="math inline">\(p\)</span> variables ortogonales denominadas componentes principales, ordenadas de manera que capturen la mayor cantidad de varianza posible y sean ortogonales.</p>
<p><strong>Formulación matemática</strong></p>
<p>Sea <span class="math inline">\(\mathbf{X}=(\mathbf{x}_1,\dots,\mathbf{x}_p) \in \mathbb{R}^{n \times p}\)</span> una matriz de datos con <span class="math inline">\(n\)</span> observaciones y <span class="math inline">\(p\)</span> variables, centrada en la media (esto es, cada columna tiene media cero). El objetivo del PCA es encontrar un conjunto de vectores <span class="math inline">\(\mathbf{W}=(\mathbf{w}_1, \mathbf{w}_2, \dots, \mathbf{w}_p)\)</span> tales que las proyecciones de los datos sobre estos vectores maximicen la varianza (cantidad de información explicada).</p>
<p>Las componentes principales vienen dadas por una combinación lineal de las variables originales <span class="math inline">\(\mathbf{x}_1,\dots,\mathbf{x}_p\)</span>, en el caso de la primera <span class="math inline">\(\mathbf{z}_1\)</span>:</p>
<p><span class="math display">\[
\mathbf{z}_1=w_{11} \mathbf{x}_1+\cdots + w_{1p} \mathbf{x}_p
\]</span></p>
<p>o, en términos matriciales</p>
<p><span class="math display">\[
\mathbf{z}_1 = \mathbf{X}\mathbf{w}_1 .
\]</span></p>
<p>La primera componente se calcula buscando que tenga la máxima varianza posible. Evidentemente, podríamos hacer la varianza de <span class="math inline">\(\mathbf{z}_1\)</span> todo lo grande que quisiéramos escogiendo valores grandes de <span class="math inline">\(w_{11},w_{12},\dots,w_{1p}\)</span>. Para evitar esto, se impone la siguiente restricción <span class="math inline">\(w^{2}_{11}+w^{2}_{12}+ \cdots + w^{2}_{1p}=1,\)</span> es decir, que el módulo del vector sea 1, <span class="math inline">\(|\mathbf{w}_1| = 1.\)</span></p>
<p>Así, lo que queremos hacer es calcular <span class="math inline">\(\mathbf{w}_1\)</span> que maximice la varianza de <span class="math inline">\(\mathbf{z}_1\)</span> con la restricción de que <span class="math inline">\(|\mathbf{w}_1| = 1\)</span>. La varianza de <span class="math inline">\(\mathbf{z}_1\)</span> es</p>
<p><span class="math display">\[
Var(\mathbf{z}_1) = \frac{1}{n}\mathbf{z}^{t}_1 \mathbf{z}_1 = \frac{1}{n}\mathbf{w}^{t}_1 \mathbf{X}^{t} \mathbf{X} \mathbf{w}_1 = \mathbf{w}^{t}_1  \mathbf{S} \mathbf{w}_1
\]</span></p>
<p>donde <span class="math inline">\(\mathbf{S} = \frac{1}{n} \mathbf{X}^{t} \mathbf{X}\)</span> es la matriz de covarianza de los datos (definida positiva). <span class="math inline">\(\mathbf{w}_1\)</span> se obtiene resolviendo el problema de optimización:</p>
<p><span class="math display">\[
\max_{\mathbf{w}_1}  \mathbf{w}_1^{t}\mathbf{S}\mathbf{w}_1, \text{   sujeto a }\mathbf{w}_1^{t}\mathbf{w}_1 = 1,
\]</span></p>
<p>Resolver este problema mediante los multiplicadores de Lagrange (os sonará de asignaturas previas como Optimización I):</p>
<p><span class="math display">\[
L(\mathbf{w}_1, \lambda_1) = \mathbf{w}_1^{t}\mathbf{S}\mathbf{w}_1 - \lambda_1(\mathbf{w}_1^{t}\mathbf{w}_1 - 1)
\]</span></p>
<p>y maximizamos la expresión derivando con respecto a <span class="math inline">\(\mathbf{w}_1\)</span> y haciendo cero la derivada:</p>
<p><span class="math display">\[
\frac{\partial L}{\partial \mathbf{w}_1} = 2\mathbf{S}\mathbf{w}_1 - 2\lambda_1 \mathbf{w}_1=0,
\]</span></p>
<p>lo que implica que <span class="math inline">\(\mathbf{S}\mathbf{w}_1 = \lambda_1 \mathbf{w}_1\)</span>.</p>
<p>Esto muestra que <span class="math inline">\(\mathbf{w}_1\)</span> es un autovector de la matriz de covarianza <span class="math inline">\(\mathbf{S}\)</span> y <span class="math inline">\(\lambda_1\)</span> es su autovalor asociado. ¿Qué autovalor es <span class="math inline">\(\lambda_1\)</span>? Si en <span class="math inline">\(\mathbf{S}\mathbf{w}_1 = \lambda_1 \mathbf{w}_1\)</span>multiplicamos por <span class="math inline">\(\mathbf{w}^{t}_1\)</span>:</p>
<p><span class="math display">\[
\underbrace{\mathbf{w}^{t}_1\mathbf{S}\mathbf{w}_1}_{Var(\mathbf{z}_1)} = \lambda_1 \underbrace{\mathbf{w}^{t}_1 \mathbf{w}_1}_{1} \Rightarrow Var(\mathbf{z}_1) = \lambda_1
\]</span></p>
<p>Como lo que se quiere maximizar es la varianza, la primera componente principal se obtiene escogiendo <span class="math inline">\(\lambda_1\)</span> como el mayor autovalor de <span class="math inline">\(\mathbf{S}\)</span>. Su autovector <span class="math inline">\(\mathbf{w}_1\)</span> nos indica los coeficientes asociados a cada una de las variables <span class="math inline">\(\mathbf{x}_j\)</span> originales para lograr la combinación lineal <span class="math inline">\(\mathbf{z}_1\)</span>.</p>
<p>Similarmente, se obtiene la segunda componente principal. Ahora buscamos maximizar la suma de las varianzas de <span class="math inline">\(\mathbf{z}_1\)</span> y <span class="math inline">\(\mathbf{z}_2\)</span>. En este caso la función de Lagrange a optimizar queda</p>
<p><span class="math display">\[
L(\mathbf{w}_2, \lambda_2) = \mathbf{w}_1^{t}\mathbf{S}\mathbf{w}_1 +\mathbf{w}_2^{t}\mathbf{S}\mathbf{w}_2 - \lambda_1(\mathbf{w}_1^{t}\mathbf{w}_1 - 1) - \lambda_2(\mathbf{w}_2^{t}\mathbf{w}_2 - 1)
\]</span></p>
<p>Como antes, derivando e igualando a 0:</p>
<p><span class="math display">\[
\frac{\partial L}{\partial \mathbf{w}_1} = 2\mathbf{S}\mathbf{w}_1 - 2\lambda_1 \mathbf{w}_1=0,
\]</span></p>
<p><span class="math display">\[
\frac{\partial L}{\partial \mathbf{w}_2} = 2\mathbf{S}\mathbf{w}_2 - 2\lambda_2 \mathbf{w}_2=0,
\]</span></p>
<p>De donde se obtiene que <span class="math inline">\(\mathbf{S}\mathbf{w}_1 = \lambda_1 \mathbf{w}_1\)</span> y que <span class="math inline">\(\mathbf{S}\mathbf{w}_2 = \lambda_2 \mathbf{w}_2\)</span><em>.</em> Esto nos vuelve a llevar a que<span class="math inline">\(\mathbf{w}_1\)</span> y <span class="math inline">\(\mathbf{w}_2\)</span> son autovectores de la matriz de covarianzas con <span class="math inline">\(\lambda_1\)</span> y <span class="math inline">\(\lambda_2\)</span> como autovalores asociados. Como antes, se escogerán los autovalores de mayor valor puesto que son los que maximizan la varianza. Además, estos dos autovectores están incorrelados (son ortogonales) dado que</p>
<p><span class="math display">\[
\mathbf{w}_1^{t} \lambda_2 \mathbf{w}_2=\mathbf{w}_1^{t} \mathbf{S}\mathbf{w}_2 \underbrace{=}_{\mathbf{S} \text{ simétrica}} \mathbf{w}_2^{t} \mathbf{S}\mathbf{w}_1 =\mathbf{w}_2^{t} \lambda_1\mathbf{w}_1
\]</span></p>
<p>y como <span class="math inline">\(\lambda_1 \neq \lambda_2 \Rightarrow \mathbf{w}_1^{t}\mathbf{w}_2= \mathbf{w}_2^{t}\mathbf{w}_1=0\)</span>, esto es, son vectores ortogonales (como además tienen norma 1, son ortonormales). Esto significa que las componentes principales <span class="math inline">\(\mathbf{z}_1\)</span> y <span class="math inline">\(\mathbf{z}_2\)</span> están incorreladas.</p>
<p>Procediendo del mismo modo se irían consiguiendo el resto de componetes principales. De forma general, se obtiene que las soluciones al problema de optimización son los autovectores <span class="math inline">\(\mathbf{w}_1, \mathbf{w}_2, \mathbf{w}_3, \dots, \mathbf{w}_p\)</span> asociados a los <span class="math inline">\(p\)</span> autovalores <span class="math inline">\(\mathbf{\lambda}=(\lambda_1,\dots,\lambda_p)\)</span> de <span class="math inline">\(\mathbf{S}\)</span>, en orden descendente. Sin pérdida de generalidad asumimos que <span class="math inline">\(\lambda_1&gt;\cdots&gt;\lambda_p\)</span> para que las componentes principales estén ordenadas por cantidad de varianza explicada.</p>
<p>Como las nuevas variables calculadas están incorreladas, la matriz de covarianzas de <span class="math inline">\(\mathbf{Z}\)</span> es</p>
<p><span class="math display">\[
\text{Var}(\mathbf{Z}) =\mathbf{S}_Z
=
\begin{bmatrix}
\lambda_1 &amp; 0 &amp; \dots &amp; 0 \\
0 &amp; \lambda_2 &amp; \dots &amp; 0 \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
0 &amp; 0 &amp; \dots &amp; \lambda_p
\end{bmatrix}
\]</span></p>
<p>Realmente, con PCA, lo que hemos hecho ha sido diagonalizar la matriz de covarianza <span class="math inline">\(\mathbf{S}\)</span> (esto equivale a encontrar una base ortonormal de autovectores en la que la matriz de covarianza sea diagonal):</p>
<p><span class="math display">\[
\mathbf{S}_Z=\text{Var}(\mathbf{Z}) = \mathbf{W}^{t}\text{Var}(\mathbf{X})\mathbf{W} = \mathbf{W}^{t}\mathbf{S}\mathbf{W}
\]</span></p>
<p>Generalmente la matriz de covarianza <span class="math inline">\(\mathbf{S}\)</span> es definida positiva (puede ser semidefinida positiva), es decir, tiene <span class="math inline">\(p\)</span> autovalores positivos. Por tanto, tendremos el mismo número de componentes principales que de variables originales:</p>
<p><span class="math display">\[
\mathbf{Z} = \mathbf{X}\mathbf{W}
\]</span></p>
<p>En resumen, calcular las componentes principales es realizar una transformación ortogonal <span class="math inline">\(\mathbf{W}\)</span> a las variables <span class="math inline">\(\mathbf{X}\)</span> (ejes originales) logrando nuevas variables <span class="math inline">\(\mathbf{Z}\)</span> que están incorreladas entre sí y que maximizan la varianza. Las nuevas variables <span class="math inline">\(\mathbf{Z}\)</span> son una combinación lineal de las originales <span class="math inline">\(\mathbf{X}\)</span> por lo que nos ayudaremos de los valores de los coeficientes <span class="math inline">\(\mathbf{W}\)</span> para interpretarlas y darles un significado.</p>
<p><strong>Porcentaje de variabilidad</strong></p>
<p>Tenemos que</p>
<p><span class="math display">\[
\text{Var}(\mathbf{Z}) = \sum_{i=1}^{p} \text{Var}(\mathbf{z}_i)=\sum_{i=1}^{p} \lambda_i =\text{traza}(\mathbf{S}_Z)
\]</span></p>
<p>Por las propiedades de la traza, <span class="math inline">\(\text{traza}(\mathbf{S}_Z) = \text{traza}(\mathbf{S})=\sum_{i=1}^{p} \text{Var}(\mathbf{x}_i)\)</span></p>
<p>Es decir, la suma de las varianzas de las variables originales y de las componentes principales coincide. Con ello, podemos especificar el porcentaje de varianza que explica cada componente principal:</p>
<p><span class="math display">\[
\frac{\lambda_i}{\sum_{i=1}^{p} \lambda_i}=\frac{\lambda_i}{\sum_{i=1}^{p} \text{Var}(\mathbf{x}_i)}
\]</span></p>
<p>Del mismo modo, se puede calcular el porcentaje de variabilidad explicada por las primeras componentes.</p>
<p><strong>Interpretación geométrica</strong></p>
<p>El procedimiento descrito equivale a realizar una rotación del sistema de coordenadas original a un nuevo sistema donde los ejes están alineados con las direcciones de máxima varianza. Los nuevos ejes (componentes principales) son ortogonales entre sí y capturan la mayor cantidad de información posible en las primeras componentes, permitiendo reducir la dimensionalidad reteniendo la información más relevante.</p>
<p>Mediante la siguiente simulación en R podemos ver la transformación que se logra tras aplicar PCA al conjunto de datos:</p>
<div class="cell">
<details class="code-fold">
<summary>Click para ver el código</summary>
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Ejemplo transformación ortonormal PCA</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Librerías</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gridExtra)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Semilla para reproducibilidad</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Datos correlacionados</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>x1 <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">2</span>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>x2 <span class="ot">&lt;-</span> <span class="fl">0.8</span> <span class="sc">*</span> x1 <span class="sc">+</span> <span class="fu">rnorm</span>(n, <span class="at">mean =</span> <span class="dv">0</span>, <span class="at">sd =</span> <span class="dv">1</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>data <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x1, x2)</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># PCA</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>pca <span class="ot">&lt;-</span> <span class="fu">prcomp</span>(data, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale. =</span> <span class="cn">TRUE</span>)</span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Guardar nuevas varialbes</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>data_pca <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(pca<span class="sc">$</span>x)</span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(data_pca) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">"PC1"</span>, <span class="st">"PC2"</span>)</span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráfico datos originales</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data, <span class="fu">aes</span>(x1, x2)) <span class="sc">+</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"blue"</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>() <span class="sc">+</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Datos originales"</span>)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># Gráfico componentes</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">ggplot</span>(data_pca, <span class="fu">aes</span>(PC1, PC2)) <span class="sc">+</span></span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color =</span> <span class="st">"red"</span>, <span class="at">alpha =</span> <span class="fl">0.6</span>) <span class="sc">+</span></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">linetype =</span> <span class="st">"dashed"</span>) <span class="sc">+</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a>  <span class="fu">coord_fixed</span>(<span class="at">ratio=</span><span class="fl">1.5</span>) <span class="sc">+</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">"Datos transformados (PCA)"</span>)</span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1, p2, <span class="at">ncol =</span> <span class="dv">2</span>)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="reddim_files/figure-html/interpret1-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<section id="pca-en-r" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="pca-en-r"><span class="header-section-number">4.1.1</span> PCA en R</h3>
<p>Trabajemos ahora con un ejemplo de datos deportivos reales. Utilizaremos estadísticas de partidos de tenis femenino (WTA), donde cada observación corresponde a un partido, y las variables recogen información básica de las jugadoras implicadas.</p>
<p>En concreto, consideraremos las siguientes variables cuantitativas:</p>
<ul>
<li><p><code>winner_rank</code>: ranking de la jugadora ganadora</p></li>
<li><p><code>loser_rank</code>: ranking de la jugadora perdedora</p></li>
<li><p><code>winner_age</code>: edad de la ganadora</p></li>
<li><p><code>loser_age</code>: edad de la perdedora</p></li>
<li><p><code>rank_diff</code>: diferencia de ranking entre perdedora y ganadora</p></li>
</ul>
<p>Nota que estas variables contienen información relevante, pero presentan escalas muy diferentes (ranking vs edad).</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Leemos y preparamos los datos </span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stderr">
<pre><code>── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
✔ dplyr     1.1.4     ✔ readr     2.1.5
✔ forcats   1.0.0     ✔ stringr   1.5.1
✔ lubridate 1.9.4     ✔ tibble    3.2.1
✔ purrr     1.0.4     ✔ tidyr     1.3.1
── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
✖ dplyr::combine() masks gridExtra::combine()
✖ dplyr::filter()  masks stats::filter()
✖ dplyr::lag()     masks stats::lag()
ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors</code></pre>
</div>
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>url_matches <span class="ot">&lt;-</span> <span class="st">"https://raw.githubusercontent.com/JeffSackmann/tennis_wta/master/wta_matches_2023.csv"</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>tennis <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(url_matches, <span class="at">show_col_types =</span> <span class="cn">FALSE</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> tennis <span class="sc">%&gt;%</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(winner_rank, loser_rank, winner_age, loser_age) <span class="sc">%&gt;%</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">drop_na</span>() <span class="sc">%&gt;%</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">rank_diff =</span> loser_rank <span class="sc">-</span> winner_rank)</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(df)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code># A tibble: 6 × 5
  winner_rank loser_rank winner_age loser_age rank_diff
        &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;
1           3         27       28.8      29.1        24
2          11         54       27.8      24          43
3           3          1       28.8      21.5        -2
4          11         48       27.8      30.8        37
5          27          6       29.1      27.4       -21
6          54        199       24        25.8       145</code></pre>
</div>
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(df)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  winner_rank        loser_rank       winner_age      loser_age    
 Min.   :   1.00   Min.   :   1.0   Min.   :15.90   Min.   :15.70  
 1st Qu.:  18.00   1st Qu.:  36.0   1st Qu.:22.80   1st Qu.:23.00  
 Median :  51.00   Median :  73.0   Median :26.10   Median :26.40  
 Mean   :  81.08   Mean   : 122.5   Mean   :26.11   Mean   :26.46  
 3rd Qu.:  95.00   3rd Qu.: 134.0   3rd Qu.:28.80   3rd Qu.:29.30  
 Max.   :1103.00   Max.   :1321.0   Max.   :43.10   Max.   :43.10  
   rank_diff       
 Min.   :-1036.00  
 1st Qu.:  -20.00  
 Median :   20.00  
 Mean   :   41.46  
 3rd Qu.:   71.00  
 Max.   : 1241.00  </code></pre>
</div>
</div>
<p>Aplicamos PCA directamente sobre las variables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prcomp</span>(df)</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Standard deviations (1, .., p=5):
[1] 2.200187e+02 1.386178e+02 4.485700e+00 4.140100e+00 1.666412e-14

Rotation (n x k) = (5 x 5):
                      PC1          PC2           PC3           PC4
winner_rank  0.0270328523  0.816047401  0.0012019482 -0.0010418434
loser_rank   0.7202354541  0.384611940  0.0009085856 -0.0006224728
winner_age  -0.0002818528 -0.001544600  0.2070064869 -0.9783383102
loser_age   -0.0004345966 -0.001162302  0.9783383659  0.2070084589
rank_diff    0.6932026018 -0.431435462 -0.0002933627  0.0004193706
                      PC5
winner_rank -5.773503e-01
loser_rank   5.773503e-01
winner_age  -3.079134e-17
loser_age   -4.640385e-17
rank_diff   -5.773503e-01</code></pre>
</div>
</div>
<p>Las <em>standard deviations</em> son los autovalores de la matriz de correlaciones, y representan la variabilidad en cada componente. A mayor valor, más relevante es la variable correspondiente a efectos de visualización. Si queremos visualizar la importancia relativa de cada componente, haremos lo siguiente:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">prcomp</span>(df))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="reddim_files/figure-html/unnamed-chunk-4-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>De modo numérico:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">prcomp</span>(df))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Importance of components:
                            PC1      PC2    PC3     PC4       PC5
Standard deviation     220.0187 138.6178 4.4857 4.14010 1.666e-14
Proportion of Variance   0.7155   0.2840 0.0003 0.00025 0.000e+00
Cumulative Proportion    0.7155   0.9994 0.9998 1.00000 1.000e+00</code></pre>
</div>
</div>
<p>Observamos que la primera componente principal explica la mayor parte de la variabilidad. Si inspeccionamos la matriz de rotaciones:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prcomp</span>(df)<span class="sc">$</span>rotation</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                      PC1          PC2           PC3           PC4
winner_rank  0.0270328523  0.816047401  0.0012019482 -0.0010418434
loser_rank   0.7202354541  0.384611940  0.0009085856 -0.0006224728
winner_age  -0.0002818528 -0.001544600  0.2070064869 -0.9783383102
loser_age   -0.0004345966 -0.001162302  0.9783383659  0.2070084589
rank_diff    0.6932026018 -0.431435462 -0.0002933627  0.0004193706
                      PC5
winner_rank -5.773503e-01
loser_rank   5.773503e-01
winner_age  -3.079134e-17
loser_age   -4.640385e-17
rank_diff   -5.773503e-01</code></pre>
</div>
</div>
<p>vemos que esta primera componente está dominada casi exclusivamente por las variables relacionadas con el ranking, mientras que las variables de edad tienen un peso mucho menor.</p>
<p>Esto no es sorprendente: los valores de <code>winner_rank</code> y <code>loser_rank</code> pueden alcanzar varios cientos, mientras que la edad suele oscilar en un rango mucho más reducido (aproximadamente entre 15 y 40 años). Como consecuencia, PCA prioriza las variables con mayor magnitud numérica.</p>
<p>¿Tiene sentido que una variable sea más influyente únicamente por estar medida en una escala mayor? Desde el punto de vista del análisis deportivo, no necesariamente.</p>
<p>Para evitar este efecto, repetimos el análisis estandarizando las variables:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">prcomp</span>(df, <span class="at">scale =</span> <span class="cn">TRUE</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="reddim_files/figure-html/unnamed-chunk-7-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">prcomp</span>(df, <span class="at">scale =</span> <span class="cn">TRUE</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Importance of components:
                         PC1    PC2    PC3    PC4       PC5
Standard deviation     1.330 1.1194 1.0061 0.9822 1.858e-16
Proportion of Variance 0.354 0.2506 0.2024 0.1929 0.000e+00
Cumulative Proportion  0.354 0.6046 0.8071 1.0000 1.000e+00</code></pre>
</div>
</div>
<p>Ahora observamos que:</p>
<ul>
<li><p>La variabilidad se reparte de forma más equilibrada entre las componentes.</p></li>
<li><p>Las dos primeras componentes explican una proporción sustancial de la variabilidad total.</p></li>
<li><p>El análisis ya no está dominado exclusivamente por el ranking.</p></li>
</ul>
<p>Antes de ir al gráfico, analicemos la matriz de rotaciones, en busca de interpretación semántica para las componentes principales:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prcomp</span>(df, <span class="at">scale =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>rotation</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                    PC1        PC2         PC3         PC4           PC5
winner_rank  0.06562643  0.8565645  0.26341406 -0.05345405 -4.355986e-01
loser_rank   0.71980188  0.2372569  0.10983299 -0.01252019  6.429420e-01
winner_age  -0.03038205 -0.2360852  0.62427646 -0.74405620 -1.387779e-17
loser_age   -0.04020540 -0.1779876  0.72382490  0.66541827 -1.387779e-17
rank_diff    0.68923064 -0.3501296 -0.07004398  0.02418277 -6.299837e-01</code></pre>
</div>
</div>
<p>En este caso, la primera componente principal puede interpretarse como una combinación global de nivel competitivo (ranking) y experiencia (edad), mientras que la segunda componente introduce contrastes entre edad y ranking. No obstante, esta interpretación no es única ni garantizada.</p>
<div class="callout callout-style-default callout-important callout-titled" title="Para recordar">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Para recordar
</div>
</div>
<div class="callout-body-container callout-body">
<p>PCA no garantiza interpretabilidad semántica. La interpretación de las componentes debe hacerse con cautela y, siempre que sea posible, con apoyo de conocimiento del dominio deportivo.</p>
</div>
</div>
<p>Proyectamos los partidos sobre las dos primeras componentes principales:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">prcomp</span>(df, <span class="at">scale =</span> <span class="cn">TRUE</span>)<span class="sc">$</span>x[, <span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>])</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="reddim_files/figure-html/unnamed-chunk-9-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>Cada punto representa un partido. Puntos cercanos indican partidos con perfiles similares en términos de ranking y edad de las jugadoras involucradas.</p>
<p>Podemos mejorar el gráfico utilizando un biplot, que incorpora información de las variables originales:</p>
<p>¿Cómo mejorar el gráfico? Un modo posible es incorporar la información de las variables utilizando la técnica del <em>biplot</em>.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">biplot</span>(<span class="fu">prcomp</span>(df, <span class="at">scale =</span> <span class="cn">TRUE</span>))</span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="reddim_files/figure-html/unnamed-chunk-10-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<p>En este gráfico:</p>
<p>Las flechas representan las variables originales.</p>
<ul>
<li><p>Su dirección y longitud indican cómo contribuyen a las componentes principales.</p></li>
<li><p>Los partidos se distribuyen según estas combinaciones latentes.</p></li>
</ul>
</section>
</section>
<section id="interpretación-y-limitaciones" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="interpretación-y-limitaciones"><span class="header-section-number">4.2</span> Interpretación y limitaciones</h2>
<p>Este análisis permite:</p>
<ul>
<li><p>Detectar patrones globales en los partidos.</p></li>
<li><p>Identificar partidos con perfiles extremos (grandes diferencias de ranking, jugadoras muy jóvenes o muy veteranas).</p></li>
<li><p>Reducir la complejidad visual del conjunto de datos.</p></li>
</ul>
<p>Sin embargo, es fundamental recordar que:</p>
<ul>
<li><p>PCA es una técnica no supervisada.</p></li>
<li><p>No utiliza información sobre el resultado del partido más allá de las variables incluidas.</p></li>
<li><p>Las componentes no representan conceptos deportivos “puros” de forma automática.</p></li>
</ul>
<p>Por tanto, PCA debe entenderse como una herramienta exploratoria, útil para visualizar y resumir datos, pero no como un sustituto del análisis específico del rendimiento o del conocimiento experto.</p>
<div class="callout callout-style-default callout-caution callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Pregunta
</div>
</div>
<div class="callout-body-container callout-body">
<p>¿Qué ocurre cuando se realiza un PCA con variables independientes?</p>
</div>
</div>
</section>
<section id="selección-de-características" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="selección-de-características"><span class="header-section-number">4.3</span> Selección de características</h2>
<p>En el tema <a href="eda.html" class="quarto-xref"><span>Capítulo 3</span></a> vimos como es posible evaluar la correlación entre una variable objetivo y las variables explicativas asociadas. A continuación, a modo de ejercicio, vamos a estudiar la relación existente entre la variable objetivo <code>deposit</code> y la variable <code>age</code> de la base de datos <code>bank</code>. Tratamos de responder a la pregunta de si la variable edad del cliente influye, o no, en si el cliente suscribirá (o no) un depósito a plazo.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="co">#library (ggplot2)</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="co">#ggplot(bank, aes(x = log(age), colour = deposit)) +</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a> <span class="co"># geom_density(lwd=2, linetype=1)</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Aprentemente, no se observa una relación significativa entre ambas variables.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="co"># df = bank %&gt;% </span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>  <span class="co">#    select(age,deposit)%&gt;%</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span class="co">#    mutate(log.age=log(age))</span></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen para los casos de depósito</span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#summary(df %&gt;% filter(deposit=="yes") %&gt;% .$log.age)</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Resumen para los casos de no depósito</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co"># summary(df %&gt;% filter(deposit=="no") %&gt;% .$log.age)</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Efectivamente, los valores de resumen de edad en ambas categorías de la variable respuesta son muy similares. Gráficamente, podemos comparar los boxplots.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="co"># ggplot(df, aes(deposit, log.age)) +</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a><span class="co">#        geom_boxplot()</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Podemos constrastar la hipótesis nula de igualdad de medias mediante un test de la T:</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># t.test(log.age ~ deposit, data = df)</span></span></code><button title="Copiar al portapapeles" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>El <span class="math inline">\(p-valor\)</span> es mayor que <span class="math inline">\(0.10\)</span> por lo que no hay evidencia estadística en las observaciones en contra de la hipótesis nula. Podemos concluir, por tanto, que no existe una relación significativa (o al menos aún no la hemos localizado) entre las variables <code>deposit</code> y <code>age</code>. Podríamos, por tanto, eliminar la varible explicativa de la base de datos. De este modo se reduce la dimensionalidad del problema. Sin embargo, es una práctica peligrosa. La variable <code>age</code> podría resultar significativamente relevante cuando se controlen los efectos de otras variables dentro del futuro modelo de ML.</p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Para recordar
</div>
</div>
<div class="callout-body-container callout-body">
<p>Eliminar variables explicativas en etapas tempranas del análisis para reducir la dimensionalidad del problema, conlleva el riesgo de pérdida de información que podría ser útil en etapas posteriores.</p>
</div>
</div>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-john1994irrelevant" class="csl-entry" role="listitem">
John, George H, Ron Kohavi, y Karl Pfleger. 1994. <span>«Irrelevant features and the subset selection problem»</span>. En <em>Machine learning proceedings 1994</em>, 121-29. Elsevier.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copiado");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copiado");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./eda.html" class="pagination-link" aria-label="Análisis Exploratorio de Datos">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Análisis Exploratorio de Datos</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./aprnosup.html" class="pagination-link" aria-label="Aprendizaje no supervisado">
        <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Aprendizaje no supervisado</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>